#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è ML Feature Pipeline
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ –∏ –≤—ã—á–∏—Å–ª—è–µ—Ç —Ñ–∏—á–∏ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python collector/scripts/run_feature_pipeline.py --symbol BTCUSDT --hours 1
    python collector/scripts/run_feature_pipeline.py --all-symbols --hours 24 --output features.csv
"""

import asyncio
import argparse
import sys
import json
import csv
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from collector.features import FeaturePipeline, FeatureStorage
    from collector.aggregates import AggregateManager
    print("‚úÖ –ú–æ–¥—É–ª–∏ feature pipeline –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install numpy pandas asyncpg")
    sys.exit(1)

class MLFeaturePipeline:
    """–ü–æ–ª–Ω—ã–π pipeline –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ ML –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.aggregate_manager = AggregateManager(connection_string)
        self.feature_pipeline = FeaturePipeline()
        self.feature_storage = FeatureStorage(connection_string)
        
    async def get_market_data_range(self, symbol: str, start_time: datetime, 
                                  end_time: datetime) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç market data –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥"""
        
        try:
            import asyncpg
            pool = await asyncpg.create_pool(self.connection_string)
            
            query = """
            SELECT 
                ts_bucket,
                symbol,
                bid_close,
                ask_close,
                spread_avg,
                microprice_avg,
                bt_ticks,
                price_close,
                volume,
                trade_count,
                vwap,
                buy_ratio,
                depth_updates
            FROM market_data_1s 
            WHERE symbol = $1
            AND ts_bucket BETWEEN $2 AND $3
            ORDER BY ts_bucket ASC
            """
            
            async with pool.acquire() as conn:
                rows = await conn.fetch(query, symbol, start_time, end_time)
                
            await pool.close()
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
            result = []
            for row in rows:
                record = dict(row)
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Decimal –≤ float
                for key, value in record.items():
                    if hasattr(value, '__float__'):
                        record[key] = float(value)
                    elif isinstance(value, datetime):
                        record[key] = value
                        
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è –µ—Å–ª–∏ –æ–Ω–∏ None
                record['bid_qty_close'] = record.get('bid_qty_close', 1.0)
                record['ask_qty_close'] = record.get('ask_qty_close', 1.0) 
                result.append(record)
                
            return result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è market data: {e}")
            return []
    
    async def get_all_symbols(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        
        try:
            import asyncpg
            pool = await asyncpg.create_pool(self.connection_string)
            
            query = """
            SELECT DISTINCT symbol 
            FROM market_data_1s 
            ORDER BY symbol
            """
            
            async with pool.acquire() as conn:
                rows = await conn.fetch(query)
                
            await pool.close()
            
            return [row['symbol'] for row in rows]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∏–º–≤–æ–ª–æ–≤: {e}")
            return []
    
    async def process_symbol_features(self, symbol: str, start_time: datetime,
                                    end_time: datetime, store_db: bool = False) -> List[Dict]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∏—á–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞"""
        
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ {symbol}: {start_time} - {end_time}")
        
        # –ü–æ–ª—É—á–∞–µ–º market data
        market_data = await self.get_market_data_range(symbol, start_time, end_time)
        
        if not market_data:
            print(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")
            return []
            
        print(f"   üìà –ù–∞–π–¥–µ–Ω–æ {len(market_data)} –∑–∞–ø–∏—Å–µ–π")
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ñ–∏—á–∏
        features_list = self.feature_pipeline.process_market_data_batch(market_data)
        
        print(f"   üî¨ –í—ã—á–∏—Å–ª–µ–Ω–æ {len(features_list)} —Ñ–∏—á–µ–π")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if store_db:
            await self.feature_storage.create_features_table()
            success = await self.feature_storage.store_features(features_list)
            if success:
                print(f"   ‚úÖ –§–∏—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")
            else:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        return [features.to_dict() for features in features_list]
    
    async def run_pipeline(self, symbols: List[str], hours: int, 
                         output_file: Optional[str] = None,
                         store_db: bool = False) -> List[Dict]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π pipeline –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤"""
        
        print("üöÄ –ó–∞–ø—É—Å–∫ ML Feature Pipeline")
        print("=" * 60)
        
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=hours)
        
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_time} - {end_time} ({hours} —á–∞—Å–æ–≤)")
        print(f"üéØ –°–∏–º–≤–æ–ª—ã: {', '.join(symbols)}")
        
        all_features = []
        
        for symbol in symbols:
            try:
                features = await self.process_symbol_features(
                    symbol, start_time, end_time, store_db
                )
                all_features.extend(features)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {symbol}: {e}")
                continue
        
        print(f"\nüìä –ò—Ç–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(all_features)} —Ñ–∏—á–µ–π")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if output_file and all_features:
            await self.save_features_to_file(all_features, output_file)
        
        return all_features
    
    async def save_features_to_file(self, features: List[Dict], filename: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∏—á–∏ –≤ —Ñ–∞–π–ª (CSV –∏–ª–∏ JSON)"""
        
        if not features:
            print("‚ö†Ô∏è –ù–µ—Ç —Ñ–∏—á–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
            
        file_path = Path(filename)
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        if filename.endswith('.csv'):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
            with open(file_path, 'w', newline='', encoding='utf-8') as f:
                if features:
                    writer = csv.DictWriter(f, fieldnames=features[0].keys())
                    writer.writeheader()
                    writer.writerows(features)
                    
            print(f"üìÑ –§–∏—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV: {file_path}")
            
        elif filename.endswith('.json'):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(features, f, indent=2, default=str)
                
            print(f"üìÑ –§–∏—á–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON: {file_path}")
            
        else:
            print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {filename}")
    
    async def generate_feature_summary(self, features: List[Dict]) -> Dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–º —Ñ–∏—á–∞–º"""
        
        if not features:
            return {}
            
        import numpy as np
        
        summary = {
            'total_records': len(features),
            'symbols': list(set(f['symbol'] for f in features)),
            'time_range': {
                'start': min(f['timestamp'] for f in features),
                'end': max(f['timestamp'] for f in features)
            },
            'feature_stats': {}
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∏—Å–ª–µ–Ω–Ω—ã–º —Ñ–∏—á–∞–º
        numeric_features = ['microprice', 'spread_rel', 'i1', 'ofi', 'volume_imbalance', 
                          'buy_volume_ratio', 'price_volatility']
        
        for feature in numeric_features:
            values = [f[feature] for f in features if f[feature] is not None]
            if values:
                summary['feature_stats'][feature] = {
                    'count': len(values),
                    'mean': float(np.mean(values)),
                    'std': float(np.std(values)),
                    'min': float(np.min(values)),
                    'max': float(np.max(values))
                }
        
        return summary

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI"""
    
    parser = argparse.ArgumentParser(description='ML Feature Pipeline –¥–ª—è market data')
    parser.add_argument('--symbol', type=str, help='–¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, BTCUSDT)')
    parser.add_argument('--all-symbols', action='store_true', 
                       help='–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã')
    parser.add_argument('--hours', type=int, default=1, 
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1)')
    parser.add_argument('--output', type=str, 
                       help='–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (CSV –∏–ª–∏ JSON)')
    parser.add_argument('--store-db', action='store_true',
                       help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∏—á–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--summary', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å —Å–≤–æ–¥–∫—É –ø–æ —Ñ–∏—á–∞–º')
    
    args = parser.parse_args()
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    if not args.symbol and not args.all_symbols:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ --symbol –∏–ª–∏ --all-symbols")
        sys.exit(1)
    
    # Connection string
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    connection_string = "postgresql://user:password@host:port/database"
    
    # –°–æ–∑–¥–∞–µ–º pipeline
    pipeline = MLFeaturePipeline(connection_string)
    
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if args.all_symbols:
            symbols = await pipeline.get_all_symbols()
            if not symbols:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
                sys.exit(1)
        else:
            symbols = [args.symbol.upper()]
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º pipeline
        features = await pipeline.run_pipeline(
            symbols=symbols,
            hours=args.hours,
            output_file=args.output,
            store_db=args.store_db
        )
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–≤–æ–¥–∫—É
        if args.summary and features:
            print("\nüìã –°–≤–æ–¥–∫–∞ –ø–æ —Ñ–∏—á–∞–º:")
            print("=" * 40)
            
            summary = await pipeline.generate_feature_summary(features)
            
            print(f"–ó–∞–ø–∏—Å–µ–π: {summary['total_records']}")
            print(f"–°–∏–º–≤–æ–ª—ã: {', '.join(summary['symbols'])}")
            print(f"–ü–µ—Ä–∏–æ–¥: {summary['time_range']['start']} - {summary['time_range']['end']}")
            
            print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∏—á–µ–π:")
            for feature, stats in summary['feature_stats'].items():
                print(f"  {feature}:")
                print(f"    mean: {stats['mean']:.6f}, std: {stats['std']:.6f}")
                print(f"    range: [{stats['min']:.6f}, {stats['max']:.6f}]")
        
        print(f"\n‚úÖ Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(features)} —Ñ–∏—á–µ–π")
        if args.output:
            print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {args.output}")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())