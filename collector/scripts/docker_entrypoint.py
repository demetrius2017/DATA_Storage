#!/usr/bin/env python3
"""
Docker Entrypoint –¥–ª—è PostgreSQL OrderBook Collector
–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Å 200 —Å–∏–º–≤–æ–ª–∞–º–∏ MM —Ñ–æ–∫—É—Å–∞
"""

import asyncio
import os
import sys
import logging
import signal
import time
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ PYTHONPATH
sys.path.insert(0, '/app')

from collector.config.symbols_mm_focused import SYMBOLS_200, validate_symbols
from collector.ingestion.batch_ingestor import BatchIngestor
from collector.monitoring.health_monitor import MonitoringSystem
from collector.database.connection import DatabaseConnection

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('/app/logs/collector.log')
    ]
)
logger = logging.getLogger(__name__)

class ProductionCollector:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è production —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.ingestor = None
        self.monitoring_system = None
        self.db_connection = None
        self.shutdown_event = asyncio.Event()
        
        # Environment variables
        self.database_url = os.getenv('DATABASE_URL')
        self.batch_size = int(os.getenv('BATCH_SIZE', '500'))
        self.flush_interval = int(os.getenv('FLUSH_INTERVAL', '30'))
        self.shards = int(os.getenv('SHARDS', '5'))
        self.monitoring_port = int(os.getenv('MONITORING_PORT', '8000'))
        
        if not self.database_url:
            raise ValueError("DATABASE_URL environment variable is required")
    
    async def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã"""
        logger.info("üîß Initializing database connection...")
        
        self.db_connection = DatabaseConnection(self.database_url)
        await self.db_connection.connect()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        schema_file = Path('/app/collector/database/schema.sql')
        if schema_file.exists():
            logger.info("üìã Creating database schema...")
            with open(schema_file, 'r') as f:
                schema_sql = f.read()
            
            await self.db_connection.execute_script(schema_sql)
            logger.info("‚úÖ Database schema created successfully")
        else:
            logger.warning("‚ö†Ô∏è Schema file not found, skipping schema creation")
    
    async def validate_symbols_config(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–∏–º–≤–æ–ª–æ–≤"""
        logger.info("üéØ Validating Market Maker symbols configuration...")
        
        try:
            validate_symbols()
            logger.info(f"‚úÖ Validated {len(SYMBOLS_200)} symbols for MM analysis")
            logger.info(f"üìä Starting with: {SYMBOLS_200[0]}")
            logger.info(f"üìä Ultra low-cap symbols: {len(SYMBOLS_200[-30:])}")
        except Exception as e:
            logger.error(f"‚ùå Symbol validation failed: {e}")
            raise
    
    async def start_batch_ingestor(self):
        """–ó–∞–ø—É—Å–∫ batch ingestor —Å 200 —Å–∏–º–≤–æ–ª–∞–º–∏"""
        logger.info("üöÄ Starting PostgreSQL batch ingestor...")
        
        config = {
            'database_url': self.database_url,
            'symbols': SYMBOLS_200,
            'batch_size': self.batch_size,
            'flush_interval': self.flush_interval,
            'shards': self.shards,
            'max_retries': int(os.getenv('MAX_RETRIES', '5')),
            'enable_monitoring': True
        }
        
        self.ingestor = BatchIngestor(config)
        
        # –ó–∞–ø—É—Å–∫ –≤ background task
        asyncio.create_task(self.ingestor.start())
        logger.info(f"‚úÖ Batch ingestor started with {len(SYMBOLS_200)} symbols")
    
    async def start_health_monitor(self):
        """–ó–∞–ø—É—Å–∫ health monitoring dashboard"""
        logger.info("üìä Starting health monitoring dashboard...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º MonitoringSystem, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–Ω–∏–º–∞–µ—Ç aiohttp dashboard —Å /health
        self.monitoring_system = MonitoringSystem(
            db_connection_string=self.database_url,
            dashboard_port=self.monitoring_port
        )
        
        # –ó–∞–ø—É—Å–∫ –≤ background task
        asyncio.create_task(self.monitoring_system.start())
        logger.info(f"‚úÖ Monitoring system started on port {self.monitoring_port}")
    
    async def wait_for_shutdown(self):
        """–û–∂–∏–¥–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ"""
        def signal_handler(signum, frame):
            logger.info(f"üì° Received signal {signum}, initiating shutdown...")
            self.shutdown_event.set()
        
        signal.signal(signal.SIGTERM, signal_handler)
        signal.signal(signal.SIGINT, signal_handler)
        
        await self.shutdown_event.wait()
    
    async def cleanup(self):
        """Graceful shutdown –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        logger.info("üîÑ Starting graceful shutdown...")
        
        tasks = []
        
        if self.ingestor:
            tasks.append(self.ingestor.stop())
        
        if self.monitoring_system:
            tasks.append(self.monitoring_system.stop())
        
        if self.db_connection:
            tasks.append(self.db_connection.close())
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
        
        logger.info("‚úÖ Cleanup completed")
    
    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        try:
            logger.info("üöÄ Starting PostgreSQL OrderBook Collector (Production)")
            logger.info(f"üéØ Market Maker Analysis Focus: {len(SYMBOLS_200)} symbols")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            await self.validate_symbols_config()
            await self.init_database()
            
            # –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            await self.start_batch_ingestor()
            await self.start_health_monitor()
            
            logger.info("üéâ All components started successfully!")
            logger.info(f"üìä Monitoring: http://localhost:{self.monitoring_port}/health")
            logger.info("üîÑ Press Ctrl+C to stop")
            
            # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            await self.wait_for_shutdown()
            
        except Exception as e:
            logger.error(f"üí• Fatal error: {e}")
            sys.exit(1)
        finally:
            await self.cleanup()

async def main():
    """Entrypoint –¥–ª—è Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    os.makedirs('/app/logs', exist_ok=True)
    os.makedirs('/app/data', exist_ok=True)
    
    # –û–∂–∏–¥–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ PostgreSQL
    logger.info("‚è≥ Waiting for PostgreSQL to be ready...")
    for attempt in range(30):
        try:
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ë–î
            import asyncpg
            database_url = os.getenv('DATABASE_URL')
            conn = await asyncpg.connect(database_url)
            await conn.close()
            logger.info("‚úÖ PostgreSQL is ready!")
            break
        except Exception as e:
            if attempt == 29:
                logger.error(f"‚ùå PostgreSQL not available after 30 attempts: {e}")
                sys.exit(1)
            logger.info(f"‚è≥ Attempt {attempt + 1}/30: PostgreSQL not ready, waiting...")
            time.sleep(2)
    
    # –ó–∞–ø—É—Å–∫ collector
    collector = ProductionCollector()
    await collector.run()

if __name__ == "__main__":
    asyncio.run(main())