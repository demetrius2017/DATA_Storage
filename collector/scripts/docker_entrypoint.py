#!/usr/bin/env python3
"""
Docker Entrypoint –¥–ª—è PostgreSQL OrderBook Collector
–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Å 200 —Å–∏–º–≤–æ–ª–∞–º–∏ MM —Ñ–æ–∫—É—Å–∞
"""

import asyncio
import os
import sys
import logging
import signal
import time
from pathlib import Path
import aiohttp

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ PYTHONPATH
sys.path.insert(0, '/app')

from collector.config.symbols_mm_focused import SYMBOLS_200, validate_symbols
from collector.ingestion.batch_ingestor import BatchIngestor
from collector.monitoring.health_monitor import MonitoringSystem
from collector.database.connection import DatabaseConnection

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('/app/logs/collector.log')
    ]
)
logger = logging.getLogger(__name__)

class ProductionCollector:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è production —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.ingestor = None
        self.monitoring_system = None
        self.db_connection = None
        self.shutdown_event = asyncio.Event()
        self.active_symbols = []
        
        # Environment variables
        self.database_url = os.getenv('DATABASE_URL')
        self.batch_size = int(os.getenv('BATCH_SIZE', '500'))
        self.flush_interval = int(os.getenv('FLUSH_INTERVAL', '30'))
        self.shards = int(os.getenv('SHARDS', '5'))
        self.monitoring_port = int(os.getenv('MONITORING_PORT', '8000'))
        self.binance_base_url = os.getenv('BINANCE_BASE_URL', 'https://fapi.binance.com').strip()
        self.binance_ws_url = os.getenv('BINANCE_WS_URL', 'wss://fstream.binance.com/ws/').strip()
        
        if not self.database_url:
            raise ValueError("DATABASE_URL environment variable is required")
    
    async def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã"""
        logger.info("üîß Initializing database connection...")
        
        self.db_connection = DatabaseConnection(self.database_url)
        await self.db_connection.connect()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        schema_file = Path('/app/collector/database/schema.sql')
        if schema_file.exists():
            logger.info("üìã Creating database schema...")
            with open(schema_file, 'r') as f:
                schema_sql = f.read()
            
            await self.db_connection.execute_script(schema_sql)
            logger.info("‚úÖ Database schema created successfully")
        else:
            logger.warning("‚ö†Ô∏è Schema file not found, skipping schema creation")
    
    async def validate_symbols_config(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–∏–º–≤–æ–ª–æ–≤"""
        logger.info("üéØ Validating Market Maker symbols configuration...")
        
        try:
            validate_symbols()
            logger.info(f"‚úÖ Validated {len(SYMBOLS_200)} symbols for MM analysis")
            logger.info(f"üìä Starting with: {SYMBOLS_200[0]}")
            logger.info(f"üìä Ultra low-cap symbols: {len(SYMBOLS_200[-30:])}")

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–∞–ª—å–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º Binance Futures USDT-–ø–µ—Ä–ø–∞–º
            self.active_symbols = await self._resolve_futures_symbols(SYMBOLS_200)
            logger.info(f"‚úÖ Resolved {len(self.active_symbols)} valid Futures symbols out of {len(SYMBOLS_200)}")
            if len(self.active_symbols) < len(SYMBOLS_200):
                missing = len(SYMBOLS_200) - len(self.active_symbols)
                logger.warning(f"‚ö†Ô∏è Filtered out {missing} symbols not present on Binance Futures USDT-perp")
        except Exception as e:
            logger.error(f"‚ùå Symbol validation failed: {e}")
            raise

    async def _resolve_futures_symbols(self, candidates):
        """–ó–∞–ø—Ä–æ—Å–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö USDT-–ø–µ—Ä–ø–µ—Ç—É–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ Binance Futures –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤."""
        base = self.binance_base_url.rstrip('/')
        url = f"{base}/fapi/v1/exchangeInfo"
        timeout = aiohttp.ClientTimeout(total=10)
        try:
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url) as resp:
                    resp.raise_for_status()
                    data = await resp.json()
                    symbols = data.get('symbols', [])
                    allowed = set(
                        s.get('symbol') for s in symbols
                        if s.get('contractType') in ('PERPETUAL', 'CURRENT_QUARTER', 'NEXT_QUARTER')
                        and s.get('status') == 'TRADING'
                        and s.get('quoteAsset') == 'USDT'
                    )
                    filtered = [sym for sym in candidates if sym in allowed]
                    return filtered
        except Exception as e:
            logger.error(f"‚ùå Failed to resolve futures symbols from {url}: {e}. Fallback to original list.")
            return list(candidates)
    
    async def start_batch_ingestor(self):
        """–ó–∞–ø—É—Å–∫ batch ingestor —Å 200 —Å–∏–º–≤–æ–ª–∞–º–∏"""
        logger.info("üöÄ Starting PostgreSQL batch ingestor...")
        logger.info(f"üåê Binance REST: {self.binance_base_url}")
        logger.info(f"üåê Binance WS:   {self.binance_ws_url}")
        
        # BatchIngestor –æ–∂–∏–¥–∞–µ—Ç —è–≤–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã: —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ, —Å–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤, –∫–∞–Ω–∞–ª—ã, —á–∏—Å–ª–æ —à–∞—Ä–¥–æ–≤
        channels = ['bookTicker', 'aggTrade']
        symbols = self.active_symbols if self.active_symbols else SYMBOLS_200
        self.ingestor = BatchIngestor(
            db_connection_string=self.database_url,
            symbols=symbols,
            channels=channels,
            shards_count=self.shards,
            ws_base_url=self.binance_ws_url,
        )
        
        # –ó–∞–ø—É—Å–∫ –≤ background task
        asyncio.create_task(self.ingestor.start())
        logger.info(f"‚úÖ Batch ingestor started with {len(symbols)} symbols")
    
    async def start_health_monitor(self):
        """–ó–∞–ø—É—Å–∫ health monitoring dashboard"""
        logger.info("üìä Starting health monitoring dashboard...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º MonitoringSystem, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–Ω–∏–º–∞–µ—Ç aiohttp dashboard —Å /health
        self.monitoring_system = MonitoringSystem(
            db_connection_string=self.database_url,
            dashboard_port=self.monitoring_port
        )
        
        # –ó–∞–ø—É—Å–∫ –≤ background task
        asyncio.create_task(self.monitoring_system.start())
        logger.info(f"‚úÖ Monitoring system started on port {self.monitoring_port}")
    
    async def wait_for_shutdown(self):
        """–û–∂–∏–¥–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ"""
        def signal_handler(signum, frame):
            logger.info(f"üì° Received signal {signum}, initiating shutdown...")
            self.shutdown_event.set()
        
        signal.signal(signal.SIGTERM, signal_handler)
        signal.signal(signal.SIGINT, signal_handler)
        
        await self.shutdown_event.wait()
    
    async def cleanup(self):
        """Graceful shutdown –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        logger.info("üîÑ Starting graceful shutdown...")
        
        tasks = []
        
        if self.ingestor:
            tasks.append(self.ingestor.stop())
        
        if self.monitoring_system:
            tasks.append(self.monitoring_system.stop())
        
        if self.db_connection:
            tasks.append(self.db_connection.close())
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
        
        logger.info("‚úÖ Cleanup completed")
    
    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        try:
            logger.info("üöÄ Starting PostgreSQL OrderBook Collector (Production)")
            logger.info(f"üéØ Market Maker Analysis Focus: {len(SYMBOLS_200)} symbols")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            await self.validate_symbols_config()
            await self.init_database()
            
            # –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            await self.start_batch_ingestor()
            await self.start_health_monitor()
            
            logger.info("üéâ All components started successfully!")
            logger.info(f"üìä Monitoring: http://localhost:{self.monitoring_port}/health")
            logger.info("üîÑ Press Ctrl+C to stop")
            
            # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            await self.wait_for_shutdown()
            
        except Exception as e:
            logger.error(f"üí• Fatal error: {e}")
            sys.exit(1)
        finally:
            await self.cleanup()

async def main():
    """Entrypoint –¥–ª—è Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞"""
    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    os.makedirs('/app/logs', exist_ok=True)
    os.makedirs('/app/data', exist_ok=True)
    
    # –û–∂–∏–¥–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ PostgreSQL
    logger.info("‚è≥ Waiting for PostgreSQL to be ready...")
    for attempt in range(30):
        try:
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ë–î
            import asyncpg
            database_url = os.getenv('DATABASE_URL')
            conn = await asyncpg.connect(database_url)
            await conn.close()
            logger.info("‚úÖ PostgreSQL is ready!")
            break
        except Exception as e:
            if attempt == 29:
                logger.error(f"‚ùå PostgreSQL not available after 30 attempts: {e}")
                sys.exit(1)
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø–µ—á–∞—Ç–∞–µ–º –ø—Ä–∏—á–∏–Ω—É, —á—Ç–æ–±—ã —É–ø—Ä–æ—Å—Ç–∏—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, firewall/SSL)
            if attempt == 0 or (attempt + 1) % 5 == 0:
                logger.warning(f"‚è≥ Attempt {attempt + 1}/30: PostgreSQL not ready: {e}")
            else:
                logger.info(f"‚è≥ Attempt {attempt + 1}/30: PostgreSQL not ready, waiting...")
            time.sleep(2)
    
    # –ó–∞–ø—É—Å–∫ collector
    collector = ProductionCollector()
    await collector.run()

if __name__ == "__main__":
    asyncio.run(main())