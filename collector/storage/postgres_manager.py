"""
üóÑÔ∏è PostgreSQL Manager –¥–ª—è OrderBook Collector
–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏ orderbook –≤ PostgreSQL —Å connection pooling
"""

import asyncio
import asyncpg
import json
import logging
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import os
from contextlib import asynccontextmanager
import ssl

@dataclass
class OrderBookData:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö orderbook –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ PostgreSQL"""
    symbol: str
    timestamp: float
    event_time: int
    first_update_id: int
    final_update_id: int
    bids: List[List[str]]
    asks: List[List[str]]
    
    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON"""
        return {
            'symbol': self.symbol,
            'timestamp': self.timestamp,
            'event_time': self.event_time,
            'first_update_id': self.first_update_id,
            'final_update_id': self.final_update_id,
            'bids': self.bids,
            'asks': self.asks
        }

class PostgreSQLManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä PostgreSQL –¥–ª—è OrderBook –¥–∞–Ω–Ω—ã—Ö
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç connection pooling, batch –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.pool: Optional[asyncpg.Pool] = None
        self.logger = logging.getLogger(__name__)
        self._batch_buffer: List[OrderBookData] = []
        self._batch_size = config.get('batch_size', 100)
        self._flush_interval = config.get('flush_interval', 5)
        self._last_flush = datetime.now()
        self._stats = {
            'total_inserts': 0,
            'batch_inserts': 0,
            'failed_inserts': 0,
            'connection_errors': 0,
            'last_insert_time': None
        }
        
    async def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è connection pool –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü"""
        try:
            self.logger.info("üîå –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è PostgreSQL connection pool...")
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            # SSL configuration according to sslmode
            sslmode = (
                self.config.get('sslmode')
                or os.getenv('DB_SSLMODE')
                or 'require'
            ).lower()

            ssl_context: ssl.SSLContext | bool
            if sslmode in ('disable', 'allow', 'prefer'):
                # allow unencrypted (not recommended); here we set False to let asyncpg decide
                ssl_context = False
            elif sslmode in ('require', 'verify-none'):
                # Encrypt without verifying server cert (closest to libpq require)
                ctx = ssl.create_default_context()
                ctx.check_hostname = False
                ctx.verify_mode = ssl.CERT_NONE
                ssl_context = ctx
            elif sslmode in ('verify-full', 'verify-ca'):
                # Strict verification using system CAs (or custom CA via SSLROOTCERT)
                cafile = os.getenv('DB_SSLROOTCERT')
                if cafile and os.path.exists(cafile):
                    ctx = ssl.create_default_context(cafile=cafile)
                else:
                    ctx = ssl.create_default_context()
                ctx.check_hostname = True
                ctx.verify_mode = ssl.CERT_REQUIRED
                ssl_context = ctx
            else:
                # Fallback to require semantics
                ctx = ssl.create_default_context()
                ctx.check_hostname = False
                ctx.verify_mode = ssl.CERT_NONE
                ssl_context = ctx

            connection_params = {
                'host': self.config['host'],
                'port': self.config['port'],
                'database': self.config['name'],
                'user': self.config['user'],
                'password': self.config['password'],
                'ssl': ssl_context,
                'min_size': max(1, self.config.get('pool_size', 20) // 10),  # –ú–∏–Ω–∏–º—É–º 1, –º–∞–∫—Å–∏–º—É–º pool_size/10
                'max_size': self.config.get('pool_size', 20),
                'command_timeout': self.config.get('pool_timeout', 60),  # –£–≤–µ–ª–∏—á–∏–ª —Ç–∞–π–º–∞—É—Ç
                'server_settings': {
                    'jit': 'off',  # –û—Ç–∫–ª—é—á–∞–µ–º JIT –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    'application_name': 'orderbook_collector'
                }
            }
            
            # –°–æ–∑–¥–∞–Ω–∏–µ pool
            self.pool = await asyncpg.create_pool(**connection_params)
            
            # –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            async with self.pool.acquire() as conn:
                version = await conn.fetchval('SELECT version()')
                self.logger.info(f"‚úÖ PostgreSQL –ø–æ–¥–∫–ª—é—á–µ–Ω: {version}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã –¥–∞–Ω–Ω—ã—Ö
            await self._create_schema()
            
            self.logger.info("üéØ PostgreSQL Manager –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ PostgreSQL: {e}")
            self._stats['connection_errors'] += 1
            return False
    
    async def _create_schema(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –∏ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è orderbook –¥–∞–Ω–Ω—ã—Ö"""
        
        schema_sql = """
        -- –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ orderbook –¥–∞–Ω–Ω—ã—Ö
        CREATE TABLE IF NOT EXISTS orderbook_data (
            id BIGSERIAL PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            timestamp DOUBLE PRECISION NOT NULL,
            event_time BIGINT NOT NULL,
            first_update_id BIGINT NOT NULL,
            final_update_id BIGINT NOT NULL,
            bids JSONB NOT NULL,
            asks JSONB NOT NULL,
            created_at TIMESTAMP DEFAULT NOW(),
            
            -- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            CONSTRAINT unique_symbol_update_id UNIQUE (symbol, final_update_id)
        );
        
        -- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        CREATE INDEX IF NOT EXISTS idx_orderbook_symbol_timestamp 
        ON orderbook_data (symbol, timestamp DESC);
        
        CREATE INDEX IF NOT EXISTS idx_orderbook_timestamp 
        ON orderbook_data (timestamp DESC);
        
        CREATE INDEX IF NOT EXISTS idx_orderbook_symbol_event_time 
        ON orderbook_data (symbol, event_time DESC);
        
        -- –ò–Ω–¥–µ–∫—Å –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        CREATE INDEX IF NOT EXISTS idx_orderbook_created_at 
        ON orderbook_data (created_at);
        
        -- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        CREATE TABLE IF NOT EXISTS collection_stats (
            id SERIAL PRIMARY KEY,
            symbol VARCHAR(20) NOT NULL,
            records_count BIGINT DEFAULT 0,
            last_update TIMESTAMP DEFAULT NOW(),
            avg_records_per_minute DOUBLE PRECISION DEFAULT 0,
            
            CONSTRAINT unique_symbol_stats UNIQUE (symbol)
        );
        """
        
        async with self.pool.acquire() as conn:
            await conn.execute(schema_sql)
            self.logger.info("‚úÖ –°—Ö–µ–º–∞ PostgreSQL —Å–æ–∑–¥–∞–Ω–∞/–æ–±–Ω–æ–≤–ª–µ–Ω–∞")
    
    async def store_orderbook(self, data: OrderBookData) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ orderbook –¥–∞–Ω–Ω—ã—Ö (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ batch buffer)"""
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
            self._batch_buffer.append(data)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –¥–ª—è flush
            should_flush = (
                len(self._batch_buffer) >= self._batch_size or
                (datetime.now() - self._last_flush).seconds >= self._flush_interval
            )
            
            if should_flush:
                await self._flush_batch()
            
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è orderbook: {e}")
            self._stats['failed_inserts'] += 1
            return False
    
    async def _flush_batch(self) -> bool:
        """–ú–∞—Å—Å–æ–≤–∞—è –≤—Å—Ç–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±—É—Ñ–µ—Ä–∞ –≤ PostgreSQL"""
        if not self._batch_buffer:
            return True
        if not self.pool:
            self.logger.error("‚ùå –û—à–∏–±–∫–∞ batch flush: connection pool is not initialized")
            # do not drop data silently; keep in buffer for later retry
            return False
        
        try:
            self.logger.debug(f"üì¶ Flush batch: {len(self._batch_buffer)} –∑–∞–ø–∏—Å–µ–π")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è batch insert
            records = []
            for data in self._batch_buffer:
                records.append((
                    data.symbol,
                    data.timestamp,
                    data.event_time,
                    data.first_update_id,
                    data.final_update_id,
                    json.dumps(data.bids),
                    json.dumps(data.asks)
                ))
            
            # Batch INSERT —Å ON CONFLICT
            insert_sql = """
                INSERT INTO orderbook_data (
                    symbol, timestamp, event_time, first_update_id, 
                    final_update_id, bids, asks
                ) VALUES ($1, $2, $3, $4, $5, $6, $7)
                ON CONFLICT (symbol, final_update_id) DO NOTHING
            """
            
            async with self.pool.acquire() as conn:
                # –í—ã–ø–æ–ª–Ω—è–µ–º batch insert
                await conn.executemany(insert_sql, records)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                await self._update_stats(conn, len(records))
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self._stats['total_inserts'] += len(records)
            self._stats['batch_inserts'] += 1
            self._stats['last_insert_time'] = datetime.now()
            
            # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
            self._batch_buffer.clear()
            self._last_flush = datetime.now()
            
            self.logger.debug(f"‚úÖ Batch flush –∑–∞–≤–µ—Ä—à–µ–Ω: {len(records)} –∑–∞–ø–∏—Å–µ–π")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ batch flush: {e}")
            self._stats['failed_inserts'] += len(self._batch_buffer)
            self._batch_buffer.clear()  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return False
    
    async def _update_stats(self, conn: asyncpg.Connection, records_count: int):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
            symbol_counts = {}
            for data in self._batch_buffer[-records_count:]:
                symbol_counts[data.symbol] = symbol_counts.get(data.symbol, 0) + 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            for symbol, count in symbol_counts.items():
                await conn.execute("""
                    INSERT INTO collection_stats (symbol, records_count, last_update)
                    VALUES ($1, $2, NOW())
                    ON CONFLICT (symbol) DO UPDATE SET
                        records_count = collection_stats.records_count + $2,
                        last_update = NOW()
                """, symbol, count)
            
        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    async def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã"""
        try:
            stats = self._stats.copy()
            
            if self.pool:
                async with self.pool.acquire() as conn:
                    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    total_records = await conn.fetchval(
                        "SELECT SUM(records_count) FROM collection_stats"
                    ) or 0
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
                    symbol_stats = await conn.fetch("""
                        SELECT symbol, records_count, last_update,
                               avg_records_per_minute
                        FROM collection_stats
                        ORDER BY records_count DESC
                    """)
                    
                    stats.update({
                        'total_records_in_db': total_records,
                        'symbols_stats': [dict(row) for row in symbol_stats],
                        'buffer_size': len(self._batch_buffer),
                        'pool_size': self.pool.get_size(),
                        'pool_idle': self.pool.get_idle_size()
                    })
            
            return stats
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return self._stats.copy()
    
    async def get_recent_data(self, symbol: str, limit: int = 100) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö orderbook –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
        try:
            async with self.pool.acquire() as conn:
                records = await conn.fetch("""
                    SELECT symbol, timestamp, event_time, first_update_id,
                           final_update_id, bids, asks, created_at
                    FROM orderbook_data
                    WHERE symbol = $1
                    ORDER BY timestamp DESC
                    LIMIT $2
                """, symbol, limit)
                
                return [
                    {
                        'symbol': row['symbol'],
                        'timestamp': row['timestamp'],
                        'event_time': row['event_time'],
                        'first_update_id': row['first_update_id'],
                        'final_update_id': row['final_update_id'],
                        'bids': json.loads(row['bids']),
                        'asks': json.loads(row['asks']),
                        'created_at': row['created_at'].isoformat()
                    }
                    for row in records
                ]
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
            return []
    
    async def cleanup_old_data(self, retention_days: int = 30) -> int:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            async with self.pool.acquire() as conn:
                result = await conn.execute("""
                    DELETE FROM orderbook_data
                    WHERE created_at < NOW() - INTERVAL '%s days'
                """, retention_days)
                
                deleted_count = int(result.split()[-1])
                self.logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π (>{retention_days} –¥–Ω–µ–π)")
                return deleted_count
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return 0
    
    async def health_check(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è PostgreSQL —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        health = {
            'pool_connected': False,
            'database_accessible': False,
            'schema_valid': False
        }
        
        try:
            if self.pool:
                health['pool_connected'] = True
                
                async with self.pool.acquire() as conn:
                    # –¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                    await conn.fetchval('SELECT 1')
                    health['database_accessible'] = True
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü
                    tables_exist = await conn.fetchval("""
                        SELECT COUNT(*) FROM information_schema.tables
                        WHERE table_name IN ('orderbook_data', 'collection_stats')
                    """)
                    health['schema_valid'] = (tables_exist == 2)
            
        except Exception as e:
            self.logger.error(f"‚ùå Health check failed: {e}")
        
        return health
    
    async def force_flush(self) -> bool:
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–ø–∏—Å—å –±—É—Ñ–µ—Ä–∞ –≤ –±–∞–∑—É"""
        return await self._flush_batch()
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π flush"""
        try:
            # –§–∏–Ω–∞–ª—å–Ω—ã–π flush –¥–∞–Ω–Ω—ã—Ö
            if self._batch_buffer:
                await self._flush_batch()
            
            # –ó–∞–∫—Ä—ã—Ç–∏–µ pool
            if self.pool:
                await self.pool.close()
                self.logger.info("üîå PostgreSQL pool –∑–∞–∫—Ä—ã—Ç")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è PostgreSQL: {e}")

    @asynccontextmanager
    async def transaction(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"""
        async with self.pool.acquire() as conn:
            async with conn.transaction():
                yield conn

# Utility functions
def create_orderbook_data(symbol: str, raw_data: Dict[str, Any]) -> OrderBookData:
    """–°–æ–∑–¥–∞–Ω–∏–µ OrderBookData –∏–∑ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö Binance"""
    return OrderBookData(
        symbol=symbol,
        timestamp=raw_data.get('E', 0) / 1000.0,  # Event time –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        event_time=raw_data.get('E', 0),
        first_update_id=raw_data.get('U', 0),
        final_update_id=raw_data.get('u', 0),
        bids=raw_data.get('b', []),
        asks=raw_data.get('a', [])
    )

async def test_postgres_manager():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ PostgreSQL Manager"""
    from dotenv import load_dotenv
    load_dotenv()
    
    config = {
        'host': os.getenv('DB_HOST'),
        'port': int(os.getenv('DB_PORT', 25060)),
        'name': os.getenv('DB_NAME'),
        'user': os.getenv('DB_USER'),
        'password': os.getenv('DB_PASSWORD'),
        'batch_size': 10,
        'flush_interval': 2,
        'pool_size': 5
    }
    
    manager = PostgreSQLManager(config)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        await manager.initialize()
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_data = OrderBookData(
            symbol='BTCUSDT',
            timestamp=datetime.now().timestamp(),
            event_time=int(datetime.now().timestamp() * 1000),
            first_update_id=12345,
            final_update_id=12346,
            bids=[['50000.00', '0.1'], ['49999.99', '0.2']],
            asks=[['50000.01', '0.15'], ['50000.02', '0.25']]
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        await manager.store_orderbook(test_data)
        await manager.force_flush()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        stats = await manager.get_stats()
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
        
        # Health check
        health = await manager.health_check()
        print(f"üè• Health: {health}")
        
        print("‚úÖ PostgreSQL Manager —Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ!")
        
    finally:
        await manager.close()

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(test_postgres_manager())