"""
–°–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –∞–≥—Ä–µ–≥–∞—Ç–∞–º–∏ TimescaleDB
–†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É: "‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ aggregates: –ù–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è bt_1s/trade_1s —Ç–∞–±–ª–∏—Ü"
"""

import asyncio
import asyncpg
import logging
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from pathlib import Path

class AggregateManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ TimescaleDB"""
    
    def __init__(self, connection_string: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
        
        Args:
            connection_string: –°—Ç—Ä–æ–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL
        """
        self.connection_string = connection_string
        self.logger = logging.getLogger(__name__)
        
    async def create_pool(self) -> asyncpg.Pool:
        """–°–æ–∑–¥–∞–µ—Ç –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        return await asyncpg.create_pool(
            self.connection_string,
            min_size=2,
            max_size=5,
            command_timeout=60
        )
        
    async def setup_continuous_aggregates(self) -> bool:
        """
        –°–æ–∑–¥–∞–µ—Ç –≤—Å–µ continuous aggregates –∏–∑ SQL —Ñ–∞–π–ª–∞
        
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            # –ß–∏—Ç–∞–µ–º SQL —Ñ–∞–π–ª
            sql_file = Path(__file__).parent.parent / "sql" / "create_continuous_aggregates.sql"
            
            if not sql_file.exists():
                self.logger.error(f"SQL —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {sql_file}")
                return False
                
            with open(sql_file, 'r', encoding='utf-8') as f:
                sql_content = f.read()
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
            sql_commands = [cmd.strip() for cmd in sql_content.split(';') if cmd.strip() and not cmd.strip().startswith('--')]
            
            pool = await self.create_pool()
            try:
                async with pool.acquire() as conn:
                    for i, command in enumerate(sql_commands):
                        if not command:
                            continue
                            
                        try:
                            self.logger.info(f"–í—ã–ø–æ–ª–Ω—è—é –∫–æ–º–∞–Ω–¥—É {i+1}/{len(sql_commands)}")
                            await conn.execute(command)
                            self.logger.debug(f"‚úÖ –ö–æ–º–∞–Ω–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: {command[:100]}...")
                            
                        except Exception as e:
                            if "already exists" in str(e).lower():
                                self.logger.info(f"–û–±—ä–µ–∫—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {command[:50]}...")
                            else:
                                self.logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã: {e}")
                                self.logger.error(f"–ö–æ–º–∞–Ω–¥–∞: {command}")
                                # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–∞–Ω–¥–æ–π
                                
                    self.logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ continuous aggregates –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")
                    return True
                    
            finally:
                await pool.close()
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ continuous aggregates: {e}")
            return False
    
    async def get_aggregate_status(self) -> Dict:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö continuous aggregates
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
        """
        try:
            pool = await self.create_pool()
            try:
                async with pool.acquire() as conn:
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–≥—Ä–µ–≥–∞—Ç–∞—Ö
                    aggregates_query = """
                    SELECT view_name, materialized_only, finalized 
                    FROM timescaledb_information.continuous_aggregates
                    """
                    
                    aggregates = await conn.fetch(aggregates_query)
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª–∏—Ç–∏–∫–∞—Ö
                    policies_query = """
                    SELECT application_name, hypertable_name, config 
                    FROM timescaledb_information.jobs 
                    WHERE application_name LIKE '%continuous_aggregate%'
                    """
                    
                    policies = await conn.fetch(policies_query)
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
                    stats = {}
                    for agg in aggregates:
                        view_name = agg['view_name']
                        try:
                            count_query = f"SELECT count(*) as cnt FROM {view_name}"
                            result = await conn.fetchrow(count_query)
                            stats[view_name] = result['cnt']
                        except Exception as e:
                            self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è {view_name}: {e}")
                            stats[view_name] = -1
                    
                    return {
                        'aggregates': [dict(agg) for agg in aggregates],
                        'policies': [dict(pol) for pol in policies],
                        'stats': stats,
                        'timestamp': datetime.utcnow().isoformat()
                    }
                    
            finally:
                await pool.close()
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤: {e}")
            return {'error': str(e)}
    
    async def refresh_aggregates(self, 
                               view_names: Optional[List[str]] = None,
                               start_time: Optional[datetime] = None,
                               end_time: Optional[datetime] = None) -> bool:
        """
        –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç continuous aggregates
        
        Args:
            view_names: –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (None = –≤—Å–µ)
            start_time: –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            end_time: –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            if view_names is None:
                view_names = ['bt_1s_continuous', 'trade_1s_continuous', 'depth_1s_continuous']
            
            if start_time is None:
                start_time = datetime.utcnow() - timedelta(hours=1)
            
            if end_time is None:
                end_time = datetime.utcnow()
            
            pool = await self.create_pool()
            try:
                async with pool.acquire() as conn:
                    for view_name in view_names:
                        try:
                            refresh_query = f"""
                            CALL refresh_continuous_aggregate('{view_name}', '{start_time}', '{end_time}')
                            """
                            await conn.execute(refresh_query)
                            self.logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω –∞–≥—Ä–µ–≥–∞—Ç: {view_name}")
                            
                        except Exception as e:
                            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è {view_name}: {e}")
                            
                    return True
                    
            finally:
                await pool.close()
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∞—Ç–æ–≤: {e}")
            return False
    
    async def get_market_data_sample(self, 
                                   symbol: str = 'BTCUSDT',
                                   limit: int = 10) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è market_data_1s
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π —Å —Ä—ã–Ω–æ—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            pool = await self.create_pool()
            try:
                async with pool.acquire() as conn:
                    query = """
                    SELECT 
                        ts_bucket,
                        symbol,
                        bid_close,
                        ask_close,
                        spread_avg,
                        microprice_avg,
                        bt_ticks,
                        price_close,
                        volume,
                        trade_count,
                        vwap,
                        buy_ratio,
                        depth_updates
                    FROM market_data_1s 
                    WHERE symbol = $1
                    ORDER BY ts_bucket DESC 
                    LIMIT $2
                    """
                    
                    rows = await conn.fetch(query, symbol, limit)
                    
                    result = []
                    for row in rows:
                        record = dict(row)
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Decimal –≤ float –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
                        for key, value in record.items():
                            if hasattr(value, '__float__'):
                                record[key] = float(value)
                            elif isinstance(value, datetime):
                                record[key] = value.isoformat()
                        result.append(record)
                    
                    return result
                    
            finally:
                await pool.close()
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è market data: {e}")
            return []
    
    async def calculate_ofi(self, 
                          symbol: str,
                          start_time: datetime,
                          end_time: datetime) -> List[Dict]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Order Flow Imbalance (OFI) –∏–∑ depth events
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞
            start_time: –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
            end_time: –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π —Å OFI
        """
        try:
            pool = await self.create_pool()
            try:
                async with pool.acquire() as conn:
                    query = """
                    WITH depth_changes AS (
                        SELECT 
                            ts_bucket,
                            symbol,
                            last_bid_price::numeric as bid_price,
                            last_ask_price::numeric as ask_price,
                            last_bid_qty::numeric as bid_qty,
                            last_ask_qty::numeric as ask_qty,
                            first_bid_price::numeric as prev_bid_price,
                            first_ask_price::numeric as prev_ask_price,
                            first_bid_qty::numeric as prev_bid_qty,
                            first_ask_qty::numeric as prev_ask_qty
                        FROM depth_1s_continuous
                        WHERE symbol = $1 
                        AND ts_bucket BETWEEN $2 AND $3
                        ORDER BY ts_bucket
                    ),
                    ofi_calc AS (
                        SELECT 
                            ts_bucket,
                            symbol,
                            bid_price,
                            ask_price,
                            bid_qty,
                            ask_qty,
                            -- OFI = (bid_qty - prev_bid_qty) –µ—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å, 
                            -- –∏–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                            CASE 
                                WHEN bid_price = prev_bid_price THEN bid_qty - prev_bid_qty
                                ELSE bid_qty
                            END as bid_flow,
                            CASE 
                                WHEN ask_price = prev_ask_price THEN ask_qty - prev_ask_qty  
                                ELSE -ask_qty
                            END as ask_flow
                        FROM depth_changes
                    )
                    SELECT 
                        ts_bucket,
                        symbol,
                        bid_price,
                        ask_price,
                        bid_flow,
                        ask_flow,
                        (bid_flow + ask_flow) as ofi,
                        bid_flow / (bid_flow + abs(ask_flow) + 0.0001) as ofi_ratio
                    FROM ofi_calc
                    ORDER BY ts_bucket
                    """
                    
                    rows = await conn.fetch(query, symbol, start_time, end_time)
                    
                    result = []
                    for row in rows:
                        record = dict(row)
                        for key, value in record.items():
                            if hasattr(value, '__float__'):
                                record[key] = float(value)
                            elif isinstance(value, datetime):
                                record[key] = value.isoformat()
                        result.append(record)
                    
                    return result
                    
            finally:
                await pool.close()
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ OFI: {e}")
            return []


async def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤"""
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º connection string –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    connection_string = "postgresql://user:password@host:port/database"
    
    manager = AggregateManager(connection_string)
    
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∞–≥—Ä–µ–≥–∞—Ç–æ–≤")
    
    # 1. –°–æ–∑–¥–∞–µ–º –∞–≥—Ä–µ–≥–∞—Ç—ã
    print("\n1. –°–æ–∑–¥–∞–Ω–∏–µ continuous aggregates...")
    success = await manager.setup_continuous_aggregates()
    if success:
        print("‚úÖ Continuous aggregates —Å–æ–∑–¥–∞–Ω—ã")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è aggregates")
        return
    
    # 2. –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—É—Å
    print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞...")
    status = await manager.get_aggregate_status()
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤: {len(status.get('aggregates', []))}")
    print(f"üìã –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–∏—Ç–∏–∫: {len(status.get('policies', []))}")
    
    for agg in status.get('aggregates', []):
        view_name = agg['view_name']
        count = status['stats'].get(view_name, 0)
        print(f"   {view_name}: {count} –∑–∞–ø–∏—Å–µ–π")
    
    # 3. –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö
    print("\n3. –û–±—Ä–∞–∑–µ—Ü market data...")
    sample = await manager.get_market_data_sample('BTCUSDT', 5)
    if sample:
        print(f"üìà –ü–æ–ª—É—á–µ–Ω–æ {len(sample)} –∑–∞–ø–∏—Å–µ–π:")
        for record in sample[:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2
            print(f"   {record['ts_bucket']}: BID={record.get('bid_close')}, ASK={record.get('ask_close')}")
    else:
        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –∞–≥—Ä–µ–≥–∞—Ç–∞—Ö (–≤–æ–∑–º–æ–∂–Ω–æ, –∫–æ–ª–ª–µ–∫—Ç–æ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–ª)")
    
    # 4. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ)
    print("\n4. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤...")
    refresh_success = await manager.refresh_aggregates()
    if refresh_success:
        print("‚úÖ –ê–≥—Ä–µ–≥–∞—Ç—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
    else:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∞—Ç–æ–≤")
    
    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    asyncio.run(main())