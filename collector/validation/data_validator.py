"""
–°–∏—Å—Ç–µ–º–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–∞–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –∑–∞–¥–∞–Ω–∏—é
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–±–∏—Ä–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö orderbook
"""

import asyncio
import logging
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from pathlib import Path
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ collector –º–æ–¥—É–ª—è–º
sys.path.insert(0, str(Path(__file__).parent.parent))

@dataclass
class ValidationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    test_name: str
    passed: bool
    details: str
    expected_value: Any = None
    actual_value: Any = None
    severity: str = "error"  # error, warning, info

@dataclass
class DataQualityReport:
    """–û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö"""
    timestamp: datetime
    total_tests: int
    passed_tests: int
    failed_tests: int
    warnings: int
    overall_score: float  # 0-100%
    results: List[ValidationResult]
    
    def to_dict(self) -> Dict:
        return {
            'timestamp': self.timestamp.isoformat(),
            'total_tests': self.total_tests,
            'passed_tests': self.passed_tests,
            'failed_tests': self.failed_tests,
            'warnings': self.warnings,
            'overall_score': self.overall_score,
            'results': [
                {
                    'test_name': r.test_name,
                    'passed': r.passed,
                    'details': r.details,
                    'expected_value': r.expected_value,
                    'actual_value': r.actual_value,
                    'severity': r.severity
                }
                for r in self.results
            ]
        }

class DataValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –∑–∞–¥–∞–Ω–∏—é"""
    
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.logger = logging.getLogger(__name__)
        
        # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –¢–ó –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        self.requirements = {
            'data_types': {
                'book_ticker': ['symbol', 'bid_price', 'bid_qty', 'ask_price', 'ask_qty', 'ts_exchange'],
                'trades': ['symbol', 'price', 'quantity', 'quote_quantity', 'is_buyer_maker', 'ts_exchange'],
                'depth_events': ['symbol', 'data', 'ts_exchange']
            },
            'update_frequency': {
                'book_ticker': 100,  # –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã –º–∞–∫—Å–∏–º—É–º –º–µ–∂–¥—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏
                'trades': 1000,      # –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                'depth_events': 100  # –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
            },
            'data_quality': {
                'price_precision': 8,    # –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π
                'quantity_precision': 8,
                'max_spread_percent': 1.0,  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å–ø—Ä–µ–¥ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
                'min_records_per_hour': 1000  # –º–∏–Ω–∏–º—É–º –∑–∞–ø–∏—Å–µ–π –≤ —á–∞—Å –¥–ª—è –∞–∫—Ç–∏–≤–Ω–æ–π –ø–∞—Ä—ã
            }
        }
    
    async def create_connection(self):
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            import asyncpg
            return await asyncpg.connect(self.connection_string)
        except ImportError:
            self.logger.error("–¢—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞: pip install asyncpg")
            return None
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            return None
    
    async def validate_table_structure(self, conn) -> List[ValidationResult]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü"""
        results = []
        
        for table_name, required_columns in self.requirements['data_types'].items():
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
                columns_query = """
                SELECT column_name, data_type, is_nullable
                FROM information_schema.columns 
                WHERE table_name = $1
                ORDER BY ordinal_position
                """
                
                columns = await conn.fetch(columns_query, table_name)
                actual_columns = [col['column_name'] for col in columns]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                missing_columns = set(required_columns) - set(actual_columns)
                
                if missing_columns:
                    results.append(ValidationResult(
                        test_name=f"Table structure: {table_name}",
                        passed=False,
                        details=f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}",
                        expected_value=required_columns,
                        actual_value=actual_columns,
                        severity="error"
                    ))
                else:
                    results.append(ValidationResult(
                        test_name=f"Table structure: {table_name}",
                        passed=True,
                        details=f"–í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç",
                        expected_value=required_columns,
                        actual_value=actual_columns,
                        severity="info"
                    ))
                    
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
                for col in columns:
                    col_name = col['column_name']
                    data_type = col['data_type']
                    
                    if col_name in ['bid_price', 'ask_price', 'price', 'quantity']:
                        if 'numeric' not in data_type.lower() and 'decimal' not in data_type.lower():
                            results.append(ValidationResult(
                                test_name=f"Data type: {table_name}.{col_name}",
                                passed=False,
                                details=f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ü–µ–Ω—ã/–∫–æ–ª–∏—á–µ—Å—Ç–≤–∞: {data_type}",
                                expected_value="NUMERIC/DECIMAL",
                                actual_value=data_type,
                                severity="warning"
                            ))
                            
            except Exception as e:
                results.append(ValidationResult(
                    test_name=f"Table structure: {table_name}",
                    passed=False,
                    details=f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}",
                    severity="error"
                ))
        
        return results
    
    async def validate_data_freshness(self, conn) -> List[ValidationResult]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å–≤–µ–∂–µ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö"""
        results = []
        
        for table_name in self.requirements['data_types'].keys():
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                freshness_query = f"""
                SELECT 
                    max(ts_exchange) as last_update,
                    count(*) as total_records,
                    count(DISTINCT symbol) as unique_symbols
                FROM {table_name}
                WHERE ts_exchange > now() - interval '1 hour'
                """
                
                result = await conn.fetchrow(freshness_query)
                
                if not result['last_update']:
                    results.append(ValidationResult(
                        test_name=f"Data freshness: {table_name}",
                        passed=False,
                        details="–ù–µ—Ç —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å",
                        expected_value="–î–∞–Ω–Ω—ã–µ –Ω–µ —Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞",
                        actual_value="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                        severity="error"
                    ))
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                last_update = result['last_update']
                age_minutes = (datetime.utcnow().replace(tzinfo=last_update.tzinfo) - last_update).total_seconds() / 60
                
                if age_minutes > 10:  # –î–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ä—à–µ 10 –º–∏–Ω—É—Ç
                    results.append(ValidationResult(
                        test_name=f"Data freshness: {table_name}",
                        passed=False,
                        details=f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ä—à–µ {age_minutes:.1f} –º–∏–Ω—É—Ç",
                        expected_value="< 10 –º–∏–Ω—É—Ç",
                        actual_value=f"{age_minutes:.1f} –º–∏–Ω—É—Ç",
                        severity="warning"
                    ))
                else:
                    results.append(ValidationResult(
                        test_name=f"Data freshness: {table_name}",
                        passed=True,
                        details=f"–î–∞–Ω–Ω—ã–µ —Å–≤–µ–∂–∏–µ: {age_minutes:.1f} –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥",
                        expected_value="< 10 –º–∏–Ω—É—Ç",
                        actual_value=f"{age_minutes:.1f} –º–∏–Ω—É—Ç",
                        severity="info"
                    ))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö
                min_records = self.requirements['data_quality']['min_records_per_hour']
                if result['total_records'] < min_records:
                    results.append(ValidationResult(
                        test_name=f"Data volume: {table_name}",
                        passed=False,
                        details=f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –∑–∞ —á–∞—Å: {result['total_records']}",
                        expected_value=f">= {min_records}",
                        actual_value=result['total_records'],
                        severity="warning"
                    ))
                else:
                    results.append(ValidationResult(
                        test_name=f"Data volume: {table_name}",
                        passed=True,
                        details=f"–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {result['total_records']} –∑–∞–ø–∏—Å–µ–π",
                        expected_value=f">= {min_records}",
                        actual_value=result['total_records'],
                        severity="info"
                    ))
                    
            except Exception as e:
                results.append(ValidationResult(
                    test_name=f"Data freshness: {table_name}",
                    passed=False,
                    details=f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–≤–µ–∂–µ—Å—Ç–∏: {e}",
                    severity="error"
                ))
        
        return results
    
    async def validate_data_quality(self, conn) -> List[ValidationResult]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö"""
        results = []
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ book_ticker –¥–∞–Ω–Ω—ã—Ö
            bt_quality_query = """
            SELECT 
                symbol,
                count(*) as records,
                avg((ask_price - bid_price) / ((ask_price + bid_price) / 2) * 100) as avg_spread_percent,
                max((ask_price - bid_price) / ((ask_price + bid_price) / 2) * 100) as max_spread_percent,
                count(CASE WHEN bid_price <= 0 OR ask_price <= 0 THEN 1 END) as invalid_prices,
                count(CASE WHEN bid_qty <= 0 OR ask_qty <= 0 THEN 1 END) as invalid_quantities,
                count(CASE WHEN ask_price <= bid_price THEN 1 END) as inverted_spread
            FROM book_ticker 
            WHERE ts_exchange > now() - interval '1 hour'
            GROUP BY symbol
            ORDER BY records DESC
            LIMIT 10
            """
            
            bt_stats = await conn.fetch(bt_quality_query)
            
            for stat in bt_stats:
                symbol = stat['symbol']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø—Ä–µ–¥
                max_spread = stat['max_spread_percent'] or 0
                if max_spread > self.requirements['data_quality']['max_spread_percent']:
                    results.append(ValidationResult(
                        test_name=f"Spread quality: {symbol}",
                        passed=False,
                        details=f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å–ø—Ä–µ–¥ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {max_spread:.3f}%",
                        expected_value=f"<= {self.requirements['data_quality']['max_spread_percent']}%",
                        actual_value=f"{max_spread:.3f}%",
                        severity="warning"
                    ))
                else:
                    results.append(ValidationResult(
                        test_name=f"Spread quality: {symbol}",
                        passed=True,
                        details=f"–°–ø—Ä–µ–¥ –≤ –Ω–æ—Ä–º–µ: max {max_spread:.3f}%",
                        expected_value=f"<= {self.requirements['data_quality']['max_spread_percent']}%",
                        actual_value=f"{max_spread:.3f}%",
                        severity="info"
                    ))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Ü–µ–Ω—ã
                if stat['invalid_prices'] > 0:
                    results.append(ValidationResult(
                        test_name=f"Price validity: {symbol}",
                        passed=False,
                        details=f"–ù–∞–π–¥–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Ü–µ–Ω—ã: {stat['invalid_prices']} –∑–∞–ø–∏—Å–µ–π",
                        expected_value="0",
                        actual_value=stat['invalid_prices'],
                        severity="error"
                    ))
                else:
                    results.append(ValidationResult(
                        test_name=f"Price validity: {symbol}",
                        passed=True,
                        details="–í—Å–µ —Ü–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã",
                        expected_value="0",
                        actual_value="0",
                        severity="info"
                    ))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø—Ä–µ–¥
                if stat['inverted_spread'] > 0:
                    results.append(ValidationResult(
                        test_name=f"Spread direction: {symbol}",
                        passed=False,
                        details=f"–ù–∞–π–¥–µ–Ω –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø—Ä–µ–¥: {stat['inverted_spread']} –∑–∞–ø–∏—Å–µ–π",
                        expected_value="0",
                        actual_value=stat['inverted_spread'],
                        severity="error"
                    ))
                else:
                    results.append(ValidationResult(
                        test_name=f"Spread direction: {symbol}",
                        passed=True,
                        details="–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–ø—Ä–µ–¥–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ",
                        expected_value="0",
                        actual_value="0",
                        severity="info"
                    ))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ trades –¥–∞–Ω–Ω—ã—Ö
            trades_quality_query = """
            SELECT 
                count(*) as total_trades,
                count(CASE WHEN price <= 0 THEN 1 END) as invalid_prices,
                count(CASE WHEN quantity <= 0 THEN 1 END) as invalid_quantities,
                avg(quantity) as avg_trade_size,
                count(CASE WHEN is_buyer_maker = true THEN 1 END) as maker_trades,
                count(CASE WHEN is_buyer_maker = false THEN 1 END) as taker_trades
            FROM trades 
            WHERE ts_exchange > now() - interval '1 hour'
            """
            
            trades_stat = await conn.fetchrow(trades_quality_query)
            
            if trades_stat:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ maker/taker
                total_trades = trades_stat['total_trades']
                if total_trades > 0:
                    maker_ratio = trades_stat['maker_trades'] / total_trades
                    if maker_ratio < 0.3 or maker_ratio > 0.7:
                        results.append(ValidationResult(
                            test_name="Maker/Taker balance",
                            passed=False,
                            details=f"–ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ maker/taker: {maker_ratio:.2%}",
                            expected_value="30-70%",
                            actual_value=f"{maker_ratio:.2%}",
                            severity="warning"
                        ))
                    else:
                        results.append(ValidationResult(
                            test_name="Maker/Taker balance",
                            passed=True,
                            details=f"–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {maker_ratio:.2%}",
                            expected_value="30-70%",
                            actual_value=f"{maker_ratio:.2%}",
                            severity="info"
                        ))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å–¥–µ–ª–∫–∏
                if trades_stat['invalid_prices'] > 0 or trades_stat['invalid_quantities'] > 0:
                    results.append(ValidationResult(
                        test_name="Trades data validity",
                        passed=False,
                        details=f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–¥–µ–ª–æ–∫: {trades_stat['invalid_prices']} —Ü–µ–Ω, {trades_stat['invalid_quantities']} –∫–æ–ª–∏—á–µ—Å—Ç–≤",
                        expected_value="0",
                        actual_value=f"{trades_stat['invalid_prices']} + {trades_stat['invalid_quantities']}",
                        severity="error"
                    ))
                else:
                    results.append(ValidationResult(
                        test_name="Trades data validity",
                        passed=True,
                        details="–í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–¥–µ–ª–æ–∫ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã",
                        expected_value="0",
                        actual_value="0",
                        severity="info"
                    ))
                    
        except Exception as e:
            results.append(ValidationResult(
                test_name="Data quality check",
                passed=False,
                details=f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö: {e}",
                severity="error"
            ))
        
        return results
    
    async def validate_update_frequency(self, conn) -> List[ValidationResult]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —á–∞—Å—Ç–æ—Ç—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –¥–∞–Ω–Ω—ã—Ö"""
        results = []
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –º–µ–∂–¥—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏
            frequency_query = """
            WITH intervals AS (
                SELECT 
                    symbol,
                    ts_exchange,
                    LAG(ts_exchange) OVER (PARTITION BY symbol ORDER BY ts_exchange) as prev_ts
                FROM book_ticker 
                WHERE ts_exchange > now() - interval '10 minutes'
            ),
            interval_stats AS (
                SELECT 
                    symbol,
                    count(*) as updates,
                    avg(EXTRACT(milliseconds FROM (ts_exchange - prev_ts))) as avg_interval_ms,
                    max(EXTRACT(milliseconds FROM (ts_exchange - prev_ts))) as max_interval_ms,
                    percentile_disc(0.95) WITHIN GROUP (ORDER BY EXTRACT(milliseconds FROM (ts_exchange - prev_ts))) as p95_interval_ms
                FROM intervals 
                WHERE prev_ts IS NOT NULL
                GROUP BY symbol
            )
            SELECT * FROM interval_stats 
            WHERE updates > 10
            ORDER BY updates DESC
            LIMIT 5
            """
            
            freq_stats = await conn.fetch(frequency_query)
            
            for stat in freq_stats:
                symbol = stat['symbol']
                avg_interval = stat['avg_interval_ms'] or 0
                max_interval = stat['max_interval_ms'] or 0
                p95_interval = stat['p95_interval_ms'] or 0
                
                expected_max = self.requirements['update_frequency']['book_ticker']
                
                if avg_interval > expected_max:
                    results.append(ValidationResult(
                        test_name=f"Update frequency: {symbol}",
                        passed=False,
                        details=f"–°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {avg_interval:.1f}ms",
                        expected_value=f"<= {expected_max}ms",
                        actual_value=f"{avg_interval:.1f}ms",
                        severity="warning"
                    ))
                else:
                    results.append(ValidationResult(
                        test_name=f"Update frequency: {symbol}",
                        passed=True,
                        details=f"–ß–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –≤ –Ω–æ—Ä–º–µ: {avg_interval:.1f}ms",
                        expected_value=f"<= {expected_max}ms",
                        actual_value=f"{avg_interval:.1f}ms",
                        severity="info"
                    ))
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ p95
                if p95_interval > expected_max * 3:  # –î–æ–ø—É—Å–∫–∞–µ–º 3x –¥–ª—è 95 –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è
                    results.append(ValidationResult(
                        test_name=f"Update consistency: {symbol}",
                        passed=False,
                        details=f"95% –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –ø—Ä–µ–≤—ã—à–∞—é—Ç –Ω–æ—Ä–º—É: {p95_interval:.1f}ms",
                        expected_value=f"<= {expected_max * 3}ms",
                        actual_value=f"{p95_interval:.1f}ms",
                        severity="warning"
                    ))
                    
        except Exception as e:
            results.append(ValidationResult(
                test_name="Update frequency check",
                passed=False,
                details=f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —á–∞—Å—Ç–æ—Ç—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π: {e}",
                severity="error"
            ))
        
        return results
    
    async def validate_continuous_aggregates(self, conn) -> List[ValidationResult]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É continuous aggregates"""
        results = []
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
            agg_query = """
            SELECT view_name, materialized_only, finalized 
            FROM timescaledb_information.continuous_aggregates
            """
            
            aggregates = await conn.fetch(agg_query)
            expected_aggregates = ['bt_1s_continuous', 'trade_1s_continuous', 'depth_1s_continuous']
            
            found_aggs = [agg['view_name'] for agg in aggregates]
            missing_aggs = set(expected_aggregates) - set(found_aggs)
            
            if missing_aggs:
                results.append(ValidationResult(
                    test_name="Continuous aggregates presence",
                    passed=False,
                    details=f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∞–≥—Ä–µ–≥–∞—Ç—ã: {missing_aggs}",
                    expected_value=expected_aggregates,
                    actual_value=found_aggs,
                    severity="error"
                ))
            else:
                results.append(ValidationResult(
                    test_name="Continuous aggregates presence",
                    passed=True,
                    details="–í—Å–µ –∞–≥—Ä–µ–≥–∞—Ç—ã —Å–æ–∑–¥–∞–Ω—ã",
                    expected_value=expected_aggregates,
                    actual_value=found_aggs,
                    severity="info"
                ))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
            for agg_name in expected_aggregates:
                if agg_name in found_aggs:
                    agg_data_query = f"""
                    SELECT 
                        count(*) as records,
                        max(ts_bucket) as last_bucket
                    FROM {agg_name}
                    WHERE ts_bucket > now() - interval '1 hour'
                    """
                    
                    agg_stat = await conn.fetchrow(agg_data_query)
                    
                    if agg_stat['records'] == 0:
                        results.append(ValidationResult(
                            test_name=f"Aggregate data: {agg_name}",
                            passed=False,
                            details="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –∞–≥—Ä–µ–≥–∞—Ç–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å",
                            expected_value="> 0",
                            actual_value="0",
                            severity="warning"
                        ))
                    else:
                        results.append(ValidationResult(
                            test_name=f"Aggregate data: {agg_name}",
                            passed=True,
                            details=f"–ê–≥—Ä–µ–≥–∞—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç {agg_stat['records']} –∑–∞–ø–∏—Å–µ–π",
                            expected_value="> 0",
                            actual_value=agg_stat['records'],
                            severity="info"
                        ))
                        
        except Exception as e:
            results.append(ValidationResult(
                test_name="Continuous aggregates check",
                passed=False,
                details=f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–≥—Ä–µ–≥–∞—Ç–æ–≤: {e}",
                severity="error"
            ))
        
        return results
    
    async def run_full_validation(self) -> DataQualityReport:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        self.logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–ª–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö...")
        
        conn = await self.create_connection()
        if not conn:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç—á–µ—Ç –æ–± –æ—à–∏–±–∫–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            return DataQualityReport(
                timestamp=datetime.utcnow(),
                total_tests=1,
                passed_tests=0,
                failed_tests=1,
                warnings=0,
                overall_score=0.0,
                results=[ValidationResult(
                    test_name="Database connection",
                    passed=False,
                    details="–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö",
                    severity="error"
                )]
            )
        
        try:
            all_results = []
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            all_results.extend(await self.validate_table_structure(conn))
            all_results.extend(await self.validate_data_freshness(conn))
            all_results.extend(await self.validate_data_quality(conn))
            all_results.extend(await self.validate_update_frequency(conn))
            all_results.extend(await self.validate_continuous_aggregates(conn))
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_tests = len(all_results)
            passed_tests = len([r for r in all_results if r.passed])
            failed_tests = len([r for r in all_results if not r.passed and r.severity == "error"])
            warnings = len([r for r in all_results if not r.passed and r.severity == "warning"])
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–π score
            if total_tests > 0:
                # –û—à–∏–±–∫–∏ —Å–Ω–∏–∂–∞—é—Ç score –±–æ–ª—å—à–µ —á–µ–º warnings
                error_penalty = failed_tests * 10
                warning_penalty = warnings * 3
                overall_score = max(0, 100 - error_penalty - warning_penalty)
            else:
                overall_score = 0
            
            return DataQualityReport(
                timestamp=datetime.utcnow(),
                total_tests=total_tests,
                passed_tests=passed_tests,
                failed_tests=failed_tests,
                warnings=warnings,
                overall_score=overall_score,
                results=all_results
            )
            
        finally:
            await conn.close()


async def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Connection string
        # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    connection_string = os.getenv("DATABASE_URL", "postgresql://user:password@host:port/database")
    
    validator = DataValidator(connection_string)
    
    print("üîç –ó–∞–ø—É—Å–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–∞–Ω–Ω—ã—Ö –¢–ó")
    print("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é
    report = await validator.run_full_validation()
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ ({report.timestamp.strftime('%Y-%m-%d %H:%M:%S')})")
    print(f"   –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {report.total_tests}")
    print(f"   –ü—Ä–æ–π–¥–µ–Ω–æ: {report.passed_tests} ‚úÖ")
    print(f"   –û—à–∏–±–∫–∏: {report.failed_tests} ‚ùå")
    print(f"   –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {report.warnings} ‚ö†Ô∏è")
    print(f"   –û–±—â–∏–π –±–∞–ª–ª: {report.overall_score:.1f}/100")
    
    print(f"\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print("-" * 60)
    
    for result in report.results:
        status_icon = "‚úÖ" if result.passed else ("‚ùå" if result.severity == "error" else "‚ö†Ô∏è")
        print(f"{status_icon} {result.test_name}")
        print(f"   {result.details}")
        if result.expected_value is not None:
            print(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: {result.expected_value}, –ü–æ–ª—É—á–µ–Ω–æ: {result.actual_value}")
        print()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_file = Path("logs/data_quality_report.json")
    report_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report.to_dict(), f, indent=2, ensure_ascii=False)
    
    print(f"üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞ –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
    if report.failed_tests > 0:
        print("\n‚ùå –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
        return 1
    elif report.warnings > 0:
        print("\n‚ö†Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏")
        return 0
    else:
        print("\n‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)